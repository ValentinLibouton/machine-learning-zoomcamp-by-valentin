{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural network\n",
    "\n",
    "Dans le chapitre précédent, nous avons vu comment créer un réseau simple. Il s'agissait d'images simples contenant peu d'informations, en noir et blanc. Les motifs se répétaient assez souvent et les formes étaient assez simples. Mais ce type d'architecture ne fonctionnerait pas avec des images plus complexes, comme celle d'un chat par exemple. Le temps de calcul serait si long qu'il deviendrait inutilisable. \n",
    "\n",
    "Pour résoudre ce type de problème, il est préférable d'utiliser une architecture dite de convolution. C'est ce que nous allons voir dans ce chapitre.\n",
    "\n",
    "\n",
    "\n",
    "## What is a convolutional ?\n",
    "\n",
    "Une convolution est une opération qui transforme une fonction en quelque chose d'autre. Les convolutions permettent de transformer la fonction d'origine en une forme permettant d'obtenir davantage d'informations.\n",
    "\n",
    "Les convolutions sont utilisées depuis longtemps dans le traitement des images pour les rendre floues et plus nettes, et pour effectuer d'autres opérations, telles que l'accentuation des bords et le gaufrage.\n",
    "\n",
    "![Conv](./img/conv.jpg)\n",
    "\n",
    "Ici, l'image originale est celle de gauche et la matrice de chiffres au milieu est la matrice de convolution ou le filtre.\n",
    "\n",
    "Une opération de convolution est une opération de multiplication de matrice par éléments. L'une des matrices est l'image et l'autre est le filtre ou le noyau qui transforme l'image en quelque chose d'autre. La sortie de cette opération est l'image convoluée finale.\n",
    "\n",
    "![schema](./img/schema.gif)\n",
    "\n",
    "Si l'image est plus grande que la taille du filtre, nous faisons glisser le filtre vers les différentes parties de l'image et effectuons l'opération de convolution. À chaque fois, nous générons un nouveau pixel dans l'image de sortie.\n",
    "\n",
    "Le nombre de pixels par lequel nous faisons glisser le noyau est connu sous le nom de \"stride\". Il est généralement fixé à 1, mais il est possible de l'augmenter. Dans ce cas, il peut être nécessaire d'augmenter la taille de l'image de quelques pixels pour faire tenir le noyau sur les bords de l'image. Cette augmentation est appelée \"padding\".\n",
    "\n",
    "Je parlerai plus en détail de la façon dont cela peut nous aider à obtenir plus d'informations à partir d'une image dans une section ultérieure.\n",
    "\n",
    "### CONVOLUTIONAL FILTERS IN MACHINE LEARNING\n",
    "\n",
    "Les convolutions ne sont pas un concept nouveau. Elles sont utilisées depuis longtemps dans le traitement des images et des signaux. Toutefois, les convolutions utilisées dans l'apprentissage automatique sont différentes de celles utilisées dans le traitement d'images.\n",
    "\n",
    "Dans le traitement d'images, il existe un ensemble de filtres qui sont utilisés pour effectuer certaines tâches. Par exemple, un filtre qui peut être utilisé pour rendre les images floues peut ressembler à ceci :\n",
    "\n",
    "![filter 2](./img/filter2.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En revanche, un filtre qui fait l'inverse, c'est-à-dire qui accentue la netteté d'une image, ressemble à ceci :\n",
    "\n",
    "![filter2](./img/04.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other filters, like sobel filters, can perform an edge detection and other operations.\n",
    "![filter 4](./img/05.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans les CNN, les filtres ne sont pas définis. La valeur de chaque filtre est apprise au cours du processus de formation.\n",
    "\n",
    "En étant capables d'apprendre les valeurs des différents filtres, les CNN peuvent trouver plus de sens dans les images que les humains et les filtres conçus par des humains ne pourraient pas trouver.\n",
    "\n",
    "Le plus souvent, les filtres d'une couche de convolution apprennent à détecter des concepts abstraits, tels que les contours d'un visage ou les épaules d'une personne. En empilant les couches de convolution les unes sur les autres, nous pouvons obtenir des informations plus abstraites et plus approfondies à partir d'un CNN.\n",
    "\n",
    "Une deuxième couche de convolution pourrait être capable de détecter la forme des yeux ou les bords d'une épaule, etc. Cela permet également aux CNN d'effectuer un apprentissage hiérarchique des caractéristiques, ce qui correspond à la façon dont notre cerveau est censé identifier les objets.\n",
    "\n",
    "![image 5](./img/06.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans l'image, on peut voir comment les différents filtres de chaque couche du CNN interprètent le chiffre 0.\n",
    "\n",
    "C'est cette capacité des CNN à détecter des caractéristiques abstraites et complexes qui les rend si intéressants dans les problèmes de reconnaissance d'images.\n",
    "\n",
    "Selon le type de problème que nous résolvons et les types de caractéristiques que nous essayons d'apprendre, nous utilisons différents types de convolutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The 2D convolution layer \n",
    "Le type de convolution le plus couramment utilisé est la couche de convolution 2D, généralement abrégée en conv2D. Un filtre ou un noyau dans une couche conv2D a une hauteur et une largeur. Ils sont généralement plus petits que l'image d'entrée et nous les déplaçons donc sur l'ensemble de l'image. La zone où le filtre se trouve sur l'image s'appelle le champ réceptif.\n",
    "\n",
    "Fonctionnement : Les filtres Conv2D s'étendent sur les trois canaux d'une image (rouge, vert et bleu). Les filtres peuvent également être différents pour chaque canal. Après que les convolutions ont été effectuées individuellement pour chaque canal, elles sont additionnées pour obtenir l'image convoluée finale. La sortie d'un filtre après une opération de convolution est appelée carte de caractéristiques.\n",
    "\n",
    "![image 7](./img/07.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaque filtre de cette couche est initialisé de manière aléatoire à une certaine distribution (normale, gaussienne, etc.). En ayant des critères d'initialisation différents, chaque filtre est entraîné légèrement différemment. Ils finissent par apprendre à détecter différentes caractéristiques de l'image.\n",
    "\n",
    "S'ils étaient tous initialisés de la même manière, les chances que deux filtres apprennent des caractéristiques similaires augmenteraient considérablement. L'initialisation aléatoire garantit que chaque filtre apprend à identifier des caractéristiques différentes.\n",
    "\n",
    "Étant donné que chaque filtre conv2D apprend une caractéristique distincte, nous en utilisons plusieurs dans une seule couche pour identifier différentes caractéristiques. Le plus intéressant est que chaque filtre est appris automatiquement.\n",
    "\n",
    "Chacun de ces filtres est utilisé comme entrée dans la couche suivante du réseau neuronal.\n",
    "\n",
    "S'il y a 8 filtres dans la première couche et 32 dans la seconde, chaque filtre de la seconde couche voit 8 entrées de filtre. Cela signifie que nous obtenons 32X8 cartes de caractéristiques dans la deuxième couche. Chacune des 8 cartes de caractéristiques d'un seul filtre est additionnée pour obtenir une seule sortie de chaque couche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What the conv2D layer is doing:**  \n",
    "\n",
    "Chaque filtre de la couche conv2D est une matrice de nombres. La matrice correspond à un motif ou à une caractéristique recherchée par le filtre.\n",
    "\n",
    "Dans l'image ci-dessous, le filtre recherche une ligne courbe. Cette ligne courbe peut correspondre au dos d'une souris ou à une partie des chiffres 8, 9, 0, etc. Chaque fois que le filtre rencontre un tel motif dans l'image, il produit un résultat élevé.\n",
    "\n",
    "\n",
    "![image 8](./img/08.jpg)\n",
    "\n",
    "Bien que cet exemple puisse sembler très simple, la plupart des filtres conv2D de la première couche d'un CNN recherchent des caractéristiques similaires. Cela signifie également que le même filtre peut être utilisé pour extraire des informations de plusieurs types d'images (souris, nombres, visages, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Where the conv2D layer is used:**  \n",
    "\n",
    "Ils sont utilisés dans les premières couches convolutives d'un CNN pour extraire des caractéristiques simples. Ils ont également été utilisés dans les réseaux de capsules. Auparavant, ils étaient les seuls filtres utilisés et constituaient la majeure partie d'un CNN. Par exemple, l'architecture LeNet originale et l'architecture AlexNet utilisaient principalement des filtres conv2D.\n",
    "\n",
    "Aujourd'hui, grâce aux progrès réalisés dans le domaine des couches convolutives et des filtres, des filtres plus sophistiqués ont été conçus, qui peuvent servir à différentes fins et être utilisés pour différentes applications. Nous en examinerons quelques-uns plus loin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to use them while designing a CNN:**  \n",
    "\n",
    "\n",
    "Les filtres Conv2D sont utilisés uniquement dans les couches initiales d'un réseau neuronal convolutif. Ils sont placés là pour extraire les caractéristiques initiales de haut niveau d'une image.\n",
    "\n",
    "Bien qu'il existe de nombreuses règles empiriques pour la conception de ces filtres, ils sont généralement empilés avec un nombre croissant de filtres dans chaque couche. Chaque couche successive peut comporter deux à quatre fois le nombre de filtres de la couche précédente. Cela permet au réseau d'apprendre des caractéristiques hiérarchiques.\n",
    "\n",
    "**Limitations of the conv2D layer:**   \n",
    "\n",
    "La couche conv2D fonctionne de manière assez impressionnante. Cependant, elle présente certaines limites, ce qui a incité les chercheurs à trouver des alternatives à la couche conv2D.\n",
    "\n",
    "Leur principale limite est qu'ils sont très coûteux en termes de calcul. Le calcul d'un filtre conv2D de grande taille prend beaucoup de temps et l'empilement de plusieurs d'entre eux en couches augmente le nombre de calculs.\n",
    "\n",
    "Une solution simple consiste à réduire la taille des filtres et à augmenter les pas. Bien que cela soit possible, cela réduit également le champ réceptif effectif du filtre et la quantité d'informations qu'il peut capturer. En fait, dans le premier article sur les réseaux convolutifs, Yann Le Cunn avait mentionné sa crainte d'avoir un filtre convolutif de 1x1.\n",
    "\n",
    "Cependant, avant d'examiner les autres types de convolutions, il est préférable d'avoir une compréhension plus intuitive des filtres.\n",
    "\n",
    "Les couches Conv2D sont généralement utilisées pour obtenir une grande précision dans les tâches de reconnaissance d'images. Cependant, elles nécessitent de nombreux calculs et sont très gourmandes en mémoire vive.\n",
    "\n",
    "Les convolutions diluées ou astrales réduisent la complexité de l'opération de convolution. Cela signifie qu'elles peuvent être utilisées dans des applications en temps réel et dans des applications où la puissance de traitement est moindre, comme dans les smartphones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Polling layer**\n",
    "\n",
    "Remarque : la mise en commun n'est pas une couche convolutive, mais nous en parlons ici, car il s'agit d'une couche couramment utilisée dans les CNN.\n",
    "\n",
    "La couche de mise en commun a été introduite pour deux raisons principales : La première est d'effectuer un sous-échantillonnage, c'est-à-dire de réduire la quantité de calculs à effectuer, et la seconde est de n'envoyer que les données importantes aux couches suivantes des CNN.\n",
    "\n",
    "Comment cela fonctionne-t-il ? Il existe deux types de couches de mise en commun : la mise en commun maximale et la mise en commun moyenne.\n",
    "\n",
    "Dans le cas du pooling max, nous ne prenons que la valeur du pixel le plus grand parmi tous les pixels du champ réceptif du filtre. Dans le cas du pooling moyen, nous prenons la moyenne de toutes les valeurs du champ réceptif.\n",
    "\n",
    "![image11](./img/11.jpg)\n",
    "\n",
    "Il existe de nombreux arguments pour déterminer lequel est le meilleur et de nombreuses règles empiriques pour savoir quand l'utiliser, mais, en général, le pooling max est plus couramment utilisé.\n",
    "\n",
    "Étant donné que nous essayons de réduire l'échantillonnage du vecteur d'entrée, les noyaux de pooling ne se chevauchent pas, c'est-à-dire qu'ils ont un pas plus grand que la taille du noyau lui-même.\n",
    "\n",
    "**Limitations of the Pooling layer:** \n",
    "\n",
    "Le déséchantillonnage par pooling pose de nombreux problèmes aux CNN.\n",
    "\n",
    "La couche de mise en commun perd des informations sur la position des différents objets dans l'image. C'est pourquoi de nombreuses nouvelles architectures ont cessé d'utiliser la couche de mise en commun.\n",
    "\n",
    "La couche de mise en commun a été introduite pour réduire le temps de calcul et la complexité en réduisant le nombre de paramètres. Avec l'augmentation de la puissance de calcul et la présence de meilleures méthodes de sous-échantillonnage, comme les convolutions séparables et dilatées, la couche de mise en commun peut être mise de côté.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us look at this in a more concrete way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons étudier les paramètres de la classe Conv2D de Keras, et nous verrons les paramètres les plus importants que vous devez régler lorsque vous entraînez vos propres réseaux neuronaux convolutifs (CNN). Nous allons ensuite utiliser la classe Conv2D de Keras pour implémenter un CNN simple. Nous allons ensuite entraîner et évaluer ce CNN sur l'ensemble de données CIFAR-10.\n",
    "\n",
    "**Objectifs**\n",
    "\n",
    "1. Déterminer rapidement si vous avez besoin d'utiliser un paramètre spécifique de la classe Conv2D de Keras.\n",
    "2. Décider d'une valeur appropriée pour ce paramètre spécifique\n",
    "3. Entraîner efficacement votre propre réseau neuronal convolutif\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let’s go ahead and get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Keras Conv2D class\n",
    "The Keras Conv2D class constructor has the following signature:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````python\n",
    "model.add(Conv2D(filters, kernel_size, strides=(1, 1),\n",
    "  padding='valid', data_format=None, dilation_rate=(1, 1),\n",
    "  activation=None, use_bias=True, kernel_initializer='glorot_uniform',\n",
    "  bias_initializer='zeros', kernel_regularizer=None,\n",
    "  bias_regularizer=None, activity_regularizer=None,\n",
    "  kernel_constraint=None, bias_constraint=None))\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks a bit overwhelming, right?\n",
    "\n",
    "How in the world are you supposed to properly set these values?\n",
    "\n",
    "No worries — let’s examine each of these parameters individually, giving you a strong understanding of not only what each parameter controls but also how to properly set each parameter as well.\n",
    "\n",
    "### Filters\n",
    "\n",
    "![image filter](./img/filters.png)\n",
    "> **Figure 1:** The Keras Conv2D parameter, filters determines the number of kernels to convolve with the input volume. Each of these operations produces a 2D activation map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first required Conv2D parameter is the number of filters  that the convolutional layer will learn.\n",
    "\n",
    "Layers early in the network architecture (i.e., closer to the actual input image) learn fewer convolutional filters while layers deeper in the network (i.e., closer to the output predictions) will learn more filters.\n",
    "\n",
    "Conv2D layers in between will learn more filters than the early Conv2D layers but fewer filters than the layers closer to the output. Let’s go ahead and take a look at an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````python \n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Activation(\"softmax\"))\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur la ligne 1, nous apprenons un total de 32 filtres. Le regroupement maximal est ensuite utilisé pour réduire les dimensions spatiales du volume de sortie.\n",
    "\n",
    "Nous apprenons ensuite 64 filtres à la ligne 4. Une fois de plus, le regroupement maximal est utilisé pour réduire les dimensions spatiales.\n",
    "\n",
    "La couche Conv2D finale apprend 128 filtres.\n",
    "\n",
    "Remarquez qu'à mesure que notre volume spatial de sortie diminue, le nombre de filtres appris augmente. Il s'agit d'une pratique courante dans la conception d'architectures CNN et je vous recommande d'en faire autant. En ce qui concerne le choix du nombre approprié de filtres, je recommande presque toujours d'utiliser des puissances de 2 comme valeurs.\n",
    "\n",
    "Vous devrez peut-être adapter la valeur exacte en fonction (1) de la complexité de votre ensemble de données et (2) de la profondeur de votre réseau neuronal, mais je recommande de commencer par des filtres de l'ordre de [32, 64, 128] dans les premières couches et d'augmenter jusqu'à [256, 512, 1024] dans les couches plus profondes.\n",
    "\n",
    "Encore une fois, la plage exacte des valeurs peut être différente pour vous, mais commencez par un plus petit nombre de filtres et n'augmentez qu'en cas de besoin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel size\n",
    "![image 12](./img/12.png)\n",
    "> **Figure 2:** The Keras deep learning Conv2D parameter, filter_size, determines the dimensions of the kernel. Common dimensions include 1×1, 3×3, 5×5, and 7×7 which can be passed as (1, 1), (3, 3), (5, 5), or (7, 7) tuples.\n",
    "\n",
    "Le deuxième paramètre que vous devez fournir à la classe Conv2D de Keras est le kernel_size , un doublet spécifiant la largeur et la hauteur de la fenêtre de convolution 2D.\n",
    "\n",
    "La taille_du_noyau doit être un entier impair.\n",
    "\n",
    "Les valeurs typiques de kernel_size sont les suivantes : (1, 1) , (3, 3) , (5, 5) , (7, 7) . Il est rare de voir des tailles de noyau supérieures à 7×7.\n",
    "\n",
    "Alors, quand utiliser chacun d'entre eux ?\n",
    "\n",
    "Si vos images d'entrée sont supérieures à 128×128, vous pouvez choisir d'utiliser une taille de noyau > 3 pour aider (1) à apprendre des filtres spatiaux plus grands et (2) à réduire la taille du volume.\n",
    "\n",
    "D'autres réseaux, tels que VGGNet, utilisent exclusivement des filtres (3, 3) dans l'ensemble du réseau.\n",
    "\n",
    "Des architectures plus avancées comme Inception, ResNet et SqueezeNet conçoivent des micro-architectures entières qui sont des \"modules\" à l'intérieur du réseau qui apprennent des caractéristiques locales à différentes échelles (c'est-à-dire 1×1, 3×3 et 5×5) et combinent ensuite les résultats.\n",
    "\n",
    "Le module Inception ci-dessous en est un bon exemple :\n",
    "\n",
    "![image13](./img/13.png)\n",
    "> **Figure 3:** The Inception/GoogLeNet CNN architecture uses “micro-architecture” modules inside the network that learn local features at different scales (filter_size) and then combine the outputs.\n",
    "\n",
    "\n",
    "The Residual module in the ResNet architecture uses 1×1 and 3×3 filters as a form of dimensionality reduction which helps to keep the number of parameters in the network low (or as low as possible given the depth of the network):\n",
    "\n",
    "![image13](./img/14.png)\n",
    "> **Figure 4:** The ResNet “Residual module” uses 1×1 and 3×3 filters for dimensionality reduction. This helps keep the overall network smaller with fewer parameters.\n",
    "\n",
    "**So, how should you choose your filter_size ?**\n",
    "\n",
    "First, examine your input image — is it larger than 128×128?\n",
    "\n",
    "If so, consider using a 5×5 or 7×7 kernel to learn larger features and then quickly reduce spatial dimensions — then start working with 3×3 kernels:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````python\n",
    "model.add(Conv2D(32, (7, 7), activation=\"relu\"))\n",
    "...\n",
    "model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "\n",
    "````\n",
    "\n",
    "If your images are smaller than 128×128 you may want to consider sticking with strictly 1×1 and 3×3 filters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strides\n",
    "\n",
    "The strides  parameter is a 2-tuple of integers, specifying the “step” of the convolution along the x and y axis of the input volume.\n",
    "\n",
    "The strides  value defaults to (1, 1) , implying that:\n",
    "\n",
    "A given convolutional filter is applied to the current location of the input volume\n",
    "The filter takes a 1-pixel step to the right and again the filter is applied to the input volume\n",
    "This process is performed until we reach the far-right border of the volume in which we move our filter one pixel down and then start again from the far left\n",
    "Typically you’ll leave the strides  parameter with the default (1, 1)  value; however, you may occasionally increase it to (2, 2)  to help reduce the size of the output volume (since the step size of the filter is larger).\n",
    "\n",
    "Typically you’ll see strides of 2×2 as a replacement to max pooling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model.add(Conv2D(128, (3, 3), strides=(1, 1), activation=\"relu\"))\n",
    "model.add(Conv2D(128, (3, 3), strides=(1, 1), activation=\"relu\"))\n",
    "model.add(Conv2D(128, (3, 3), strides=(2, 2), activation=\"relu\"))\n",
    "```\n",
    "\n",
    "Here we can see our first two Conv2D layers have a stride of 1×1. The final Conv2D layer; however, takes the place of a max pooling layer, and instead reduces the spatial dimensions of the output volume via strided convolution.\n",
    "\n",
    "In 2014, Springenber et al. published a paper entitled Striving for Simplicity: [The All Convolutional](https://arxiv.org/abs/1412.6806) Net which demonstrated that replacing pooling layers with strided convolutions can increase accuracy in some situations.\n",
    "\n",
    "ResNet, a popular CNN, has embraced this finding — if you ever look at the source code to a ResNet implementation (or implement it yourself), you’ll see that ResNet replies on strided convolution rather than max pooling to reduce spatial dimensions in between residual modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T10:19:48.429017820Z",
     "start_time": "2024-01-25T10:19:48.367368779Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding\n",
    "\n",
    "![image15](./img/15.gif)\n",
    "> **Figure 5:** A 3×3 kernel applied to an image with padding. The Keras Conv2D padding parameter accepts either \"valid\" (no padding) or \"same\" (padding + preserving spatial dimensions). This animation was contributed to StackOverflow [(source)](https://stackoverflow.com/questions/52067833/how-to-plot-an-animated-matrix-in-matplotlib).\n",
    "\n",
    "The padding  parameter to the Keras Conv2D class can take on one of two values: valid  or same .\n",
    "\n",
    "With the valid  parameter the input volume is not zero-padded and the spatial dimensions are allowed to reduce via the natural application of convolution.\n",
    "\n",
    "The following example would naturally reduce the spatial dimensions of our volume:\n",
    "\n",
    "```Python\n",
    "model.add(Conv2D(32, (3, 3), padding=\"valid\"))\n",
    "```\n",
    "\n",
    "If you instead want to preserve the spatial dimensions of the volume such that the output volume size matches the input volume size, then you would want to supply a value of same  for the padding :\n",
    "\n",
    "```Python\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "```\n",
    "\n",
    "While the default Keras Conv2D value is valid  I will typically set it to same  for the majority of the layers in my network and then either reduce spatial dimensions of my volume by either:  \n",
    "\n",
    "1. Max pooling\n",
    "2. Strided convolution\n",
    "\n",
    "I would recommend that you use a similar approach to padding with the Keras Conv2D class as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data_format\n",
    "\n",
    "![image 16](./img/16.png)\n",
    "> **Figure 6:** Keras, as a high-level framework, supports multiple deep learning backends. Thus, it includes support for both “channels last” and “channels first” channel ordering.\n",
    "\n",
    "\n",
    "\n",
    "The data format value in the Conv2D class can be either channels_last  or channels_first :\n",
    "\n",
    "- The TensorFlow backend to Keras uses channels last ordering.\n",
    "- The Theano backend uses channels first ordering.\n",
    "\n",
    "You typically shouldn’t have to ever touch this value as Keras for two reasons:\n",
    "\n",
    "1. You are more than likely using the TensorFlow backend to Keras\n",
    "2. And if not, you’ve likely already updated your ~/.keras/keras.json  configuration file to set your backend and associated channel ordering\n",
    "\n",
    "My advice is to never explicitly set the data_format  in your Conv2D class unless you have a very good reason to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dilation_rate \n",
    "\n",
    "![image 17](./img/17.png)\n",
    "> **Figure 7:** The Keras deep learning Conv2D parameter, dilation_rate, accepts a 2-tuple of integers to control dilated convolution [(source)](http://www.erogol.com/dilated-convolution/).\n",
    "\n",
    "The dilation_rate  parameter of the Conv2D class is a 2-tuple of integers, controlling the dilation rate for dilated convolution. Dilated convolution is a basic convolution only applied to the input volume with defined gaps, as Figure 7 above demonstrates.\n",
    "\n",
    "You may use dilated convolution when:\n",
    "\n",
    "You are working with higher resolution images but fine-grained details are still important\n",
    "You are constructing a network with fewer parameters\n",
    "Discussing dilated convolution is outside the scope of this tutorial so if you are interested in learning more, please [refer to this tutorial](https://medium.com/@erogol/small-notes-on-dilated-convolution-abdcae62e8ea)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### activation \n",
    "![activation](./img/18.png)\n",
    "> **Figure 8:** Keras provides a number of common activation functions. The activation parameter to Conv2D is a matter of convenience and allows the activation function for use after convolution to be specified.\n",
    "\n",
    "\n",
    "\n",
    "The activation  parameter to the Conv2D class is simply a convenience parameter, allowing you to supply a string specifying the name of the activation function you want to apply after performing the convolution.\n",
    "\n",
    "In the following example we perform convolution and then apply a ReLU activation function:  \n",
    "\n",
    "````python\n",
    "model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "\n",
    "````\n",
    "\n",
    "The above code is equivalent to:\n",
    "\n",
    "````python\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "````\n",
    "Use the activation  parameter if you and if it helps keep your code cleaner — it’s entirely up to you and won’t have an impact on the performance of your Convolutional Neural Network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use_bias\n",
    "The use_bias  parameter of the Conv2D class controls whether a bias vector is added to the convolutional layer.\n",
    "\n",
    "Typically you’ll want to leave this value as True , although some implementations of ResNet will leave the bias parameter out.\n",
    "\n",
    "I recommend keep the bias unless you have a good reason not to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kernel_initializer and bias_initializer\n",
    "![19](./img/19.png)\n",
    "\n",
    "> **Figure 9:** Keras offers a number of initializers for the Conv2D class. Initializers can be used to help train deeper neural networks more effectively.\n",
    "\n",
    "The kernel_initializer  controls the initialization method used to initialize all values in the Conv2D class prior to actually training the network.\n",
    "\n",
    "Similarly, the bias_initializer  controls how the bias vector is initialized before training starts.\n",
    "\n",
    "A full list of initializers can be found in the Keras documentation; however, here is what I recommend:\n",
    "\n",
    "1. Leave the bias_initialization  alone — it will by default filled with zeros (you’ll rarely if ever, have to change the bias initialization method.  \n",
    "\n",
    "\n",
    "2. The kernel_initializer  defaults to glorot_uniform , the Xavier Glorot uniform initialization method, which is perfectly fine for the majority of tasks; however, for deeper neural networks you may want to use  he_normal  (MSRA/He et al. initialization) which works especially well when your network has a large number of parameters (i.e., VGGNet).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kernel_regularizer, bias_regularizer, and activity_regularizer\n",
    "![20](./img/20.png)\n",
    "\n",
    "> **Figure 10:** Regularization hyperparameters should be adjusted especially when working with large datasets and really deep networks. The kernel_regularizer parameter in particular is one that I adjust often to reduce overfitting and increase the ability for a model to generalize to unfamiliar images.\n",
    "\n",
    "The kernel_regularizer , bias_regularizer , and activity_regularizer  control the type and amount of regularization method applied to the Conv2D layer.\n",
    "\n",
    "Applying regularization helps you to:\n",
    "\n",
    "1. Reduce the effects of overfitting\n",
    "2. Increase the ability of your model to generalize\n",
    "\n",
    "**When working with large datasets and deep neural networks applying regularization is typically a must.**\n",
    "\n",
    "Normally you’ll encounter either L1 or L2 regularization being applied — I will use L2 regularization on my networks if I detect signs of overfitting:\n",
    "\n",
    "```python\n",
    "from keras.regularizers import l2\n",
    "...\n",
    "model.add(Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "\tkernel_regularizer=l2(0.0005))\n",
    "```\n",
    "\n",
    "\n",
    "The amount of regularization you apply is a hyperparameter you will need to tune for your own dataset, but I find values of 0.0001-0.001 are good ranges to start with.\n",
    "\n",
    "I would suggest leaving your bias regularizer alone — regularizing the bias typically has very little impact on reducing overfitting.\n",
    "\n",
    "I also suggest leaving the activity_regularizer  at its default value (i.e., no activity regularization).\n",
    "\n",
    "While weight regularization methods operate on weights themselves, f(W), where f is the activation function and W are the weights, an activity regularizer instead operates on the outputs, f(O), where O is the outputs of a layer.\n",
    "\n",
    "Unless there is a very specific reason you’re looking to regularize the output it’s best to leave this parameter alone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kernel_constraint and bias_constraint\n",
    "\n",
    "The final two parameters to the Keras Conv2D class are the kernel_constraint  and bias_constraint .\n",
    "\n",
    "These parameters allow you to impose constraints on the Conv2D layer, including non-negativity, unit normalization, and min-max normalization.\n",
    "\n",
    "You can see the full list of supported constraints in the Keras documentation.\n",
    "\n",
    "Again, I would recommend leaving both the kernel constraint and bias constraint alone unless you have a specific reason to impose constraints on the Conv2D layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10 Photo Classification Dataset\n",
    "CIFAR is an acronym that stands for the Canadian Institute For Advanced Research and the CIFAR-10 dataset was developed along with the CIFAR-100 dataset by researchers at the CIFAR institute.\n",
    "\n",
    "The dataset is comprised of 60,000 32×32 pixel color photographs of objects from 10 classes, such as frogs, birds, cats, ships, etc. The class labels and their standard associated integer values are listed below.\n",
    "\n",
    "0. airplane\n",
    "1. automobile\n",
    "2. bird\n",
    "3. cat\n",
    "4. deer\n",
    "5. dog\n",
    "6. frog\n",
    "7. horse\n",
    "8. ship\n",
    "9. truck\n",
    "\n",
    "These are very small images, much smaller than a typical photograph, and the dataset was intended for computer vision research.\n",
    "\n",
    "CIFAR-10 is a well-understood dataset and widely used for benchmarking computer vision algorithms in the field of machine learning. The problem is “solved.” It is relatively straightforward to achieve 80% classification accuracy. Top performance on the problem is achieved by deep learning convolutional neural networks with a classification accuracy above 90% on the test dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import plug-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T10:26:55.434802151Z",
     "start_time": "2024-01-25T10:26:55.376285333Z"
    }
   },
   "outputs": [],
   "source": [
    "# example of loading the cifar10 dataset\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import regularizers\n",
    "from keras import optimizers \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#tf.logging.set_verbosity(tf.logging.ERROR) # this line is for hiding the futerwarning of tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As a good practice suggests, we need to declare our variables:\n",
    "\n",
    "- *batch_size* – the number of training examples in one forward/ backwards pass. The higher the batch size, the more memory space you’ll need\n",
    "- *num_classes* – number of cifar-10 dataset classes\n",
    "- *one epoch* – one forward pass and one backward pass of all the training examples\n",
    "- *class_names* – an array includes all 10 class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T10:26:59.381559040Z",
     "start_time": "2024-01-25T10:26:59.333276364Z"
    }
   },
   "outputs": [],
   "source": [
    "# Declare variables\n",
    "batch_size = 32 # 32 examples in a mini-batch, smaller batch size means more updates in one epoch\n",
    "num_classes = 10 # number of outputs possible\n",
    "epochs =  50 # repeat \n",
    "class_names = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T10:27:00.523531397Z",
     "start_time": "2024-01-25T10:27:00.303819308Z"
    }
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print figure with 10 random images from the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T10:27:02.223969632Z",
     "start_time": "2024-01-25T10:27:01.796974282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 800x300 with 10 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print figure with 10 random images from each\n",
    "fig = plt.figure(figsize=(8,3))\n",
    "for i in range(num_classes):\n",
    "    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
    "    idx = np.where(y_train[:]==i)[0]\n",
    "    features_idx = x_train[idx,::]\n",
    "    img_num = np.random.randint(features_idx.shape[0])\n",
    "    im = np.transpose(features_idx[img_num,::],(0,1,2))\n",
    "    ax.set_title(class_names[i])\n",
    "    plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized data\n",
    "It’s good practice to work with normalized data.\n",
    "\n",
    "Because the input values are well understood, we can easily normalize to the range 0 to 1 by dividing each value by the maximum observation which is 255.\n",
    "\n",
    "Note, the data is loaded as integers, so we must cast it to float point values in order to perform the division.\n",
    "\n",
    "**Exercise :** \n",
    "1. Cast x_train & x_test in ``float32``.\n",
    "2. Normalize the data so that they have a value in 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T10:27:02.593553316Z",
     "start_time": "2024-01-25T10:27:02.560016007Z"
    }
   },
   "outputs": [],
   "source": [
    "### Enter your code here (4 lines)\n",
    "\n",
    "\n",
    "\n",
    "### End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise :** Transform y data into categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T10:00:30.322896957Z",
     "start_time": "2024-01-25T10:00:30.312953428Z"
    }
   },
   "outputs": [],
   "source": [
    "### Enter your code here (2 lines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T10:00:31.073589208Z",
     "start_time": "2024-01-25T10:00:31.035983015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=(50000, 32, 32, 3), y=(50000, 1)\n",
      "Test: X=(10000, 32, 32, 3), y=(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Summarize loaded dataset\n",
    "print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
    "print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let’s start by defining a simple CNN model. *(4 layers)*\n",
    "\n",
    "We will use a model with four convolutional layers followed by max pooling and a flattening out of the network to fully connected layers to make predictions:\n",
    "\n",
    "1. Convolutional input layer, 32 feature maps with a size of 3×3, a rectifier activation function\n",
    "2. Convolutional input layer, 32 feature maps with a size of 3×3, a rectifier activation function\n",
    "3. Max Pool layer with size 2×2\n",
    "4. Dropout set to 25%\n",
    "5. Convolutional input layer, 64 feature maps with a size of 3×3, a rectifier activation function\n",
    "6. Convolutional input layer, 64 feature maps with a size of 3×3, a rectifier activation function\n",
    "7. Max Pool layer with size 2×2\n",
    "8. Dropout set to 25%\n",
    "9. Flatten layer\n",
    "10. Fully connected layer with 512 units and a rectifier activation function\n",
    "11. Dropout set to 50%\n",
    "12. Fully connected output layer with 10 units and a softmax activation function\n",
    "\n",
    "A logarithmic loss function is used with the stochastic gradient descent (SGD) optimization algorithm configured with a large momentum and weight decay start with a learning rate of 0.1.\n",
    "\n",
    "Then we can fit this model with 50 epochs and a batch size of 32.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T09:51:19.472399977Z",
     "start_time": "2024-01-25T09:51:19.464084981Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 23\u001B[0m\n\u001B[1;32m     20\u001B[0m     model\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n\u001B[0;32m---> 23\u001B[0m cnn_4 \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_4_layers\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[2], line 3\u001B[0m, in \u001B[0;36mmodel_4_layers\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmodel_4_layers\u001B[39m():\n\u001B[0;32m----> 3\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mSequential\u001B[49m()\n\u001B[1;32m      4\u001B[0m     model\u001B[38;5;241m.\u001B[39madd(Conv2D(\u001B[38;5;241m32\u001B[39m, (\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m3\u001B[39m), padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msame\u001B[39m\u001B[38;5;124m'\u001B[39m, input_shape\u001B[38;5;241m=\u001B[39mx_train\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m:], activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrelu\u001B[39m\u001B[38;5;124m'\u001B[39m)) \u001B[38;5;66;03m# Layer 1\u001B[39;00m\n\u001B[1;32m      5\u001B[0m     model\u001B[38;5;241m.\u001B[39madd(Conv2D(\u001B[38;5;241m32\u001B[39m,(\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m3\u001B[39m), activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrelu\u001B[39m\u001B[38;5;124m'\u001B[39m )) \u001B[38;5;66;03m# Layer 2\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "def model_4_layers():\n",
    " \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:], activation='relu')) # Layer 1\n",
    "    model.add(Conv2D(32,(3, 3), activation='relu' )) # Layer 2\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    " \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu')) # Layer 3\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu')) # Layer 4\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    " \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512,activation='relu' ))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile model \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "cnn_4 = model_4_layers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T09:51:19.864261477Z",
     "start_time": "2024-01-25T09:51:19.828634294Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnn_4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mcnn_4\u001B[49m\u001B[38;5;241m.\u001B[39msummary()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'cnn_4' is not defined"
     ]
    }
   ],
   "source": [
    "cnn_4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model\n",
    "![https://www.theux.be/fr/ma-commune/services-communaux/attention.jpg/@@images/image.jpeg](https://www.theux.be/fr/ma-commune/services-communaux/attention.jpg/@@images/image.jpeg)\n",
    "Be careful, training the model with convolution networks is resource-intensive.  \n",
    "If you have a good graphics card it is then better to configure your python environment to use your gpu. \n",
    "\n",
    "In my case, a \"gpu\" environment was already preconfigured with Anaconda. If this is not your case, you will have to do a small google search.\n",
    "\n",
    "The time saving is not negligible, by doing tests, I could see that the training was done 5 times faster using the gpu. (21 seconds per epoch instead of 110 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's go !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T09:51:20.480614885Z",
     "start_time": "2024-01-25T09:51:20.445088630Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnn_4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m cnn4 \u001B[38;5;241m=\u001B[39m \u001B[43mcnn_4\u001B[49m\u001B[38;5;241m.\u001B[39mfit(x_train, y_train, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, epochs\u001B[38;5;241m=\u001B[39mepochs, validation_data\u001B[38;5;241m=\u001B[39m(x_test,y_test), shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'cnn_4' is not defined"
     ]
    }
   ],
   "source": [
    "cnn4 = cnn_4.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test,y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T09:51:20.663665151Z",
     "start_time": "2024-01-25T09:51:20.633452045Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnn_4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m scores4l \u001B[38;5;241m=\u001B[39m \u001B[43mcnn_4\u001B[49m\u001B[38;5;241m.\u001B[39mevaluate(x_test, y_test, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccuracy: \u001B[39m\u001B[38;5;132;01m%.2f\u001B[39;00m\u001B[38;5;132;01m%%\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (scores4l[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m100\u001B[39m))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'cnn_4' is not defined"
     ]
    }
   ],
   "source": [
    "scores4l = cnn_4.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores4l[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**My scrore**  \n",
    "Accuracy: 79.73%  \n",
    "Epochs : 50  \n",
    "Btach_size : 32  \n",
    "Time : 17 min  \n",
    "GPU : GTX 1050  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T09:51:21.287620454Z",
     "start_time": "2024-01-25T09:51:21.255441124Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnn_4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mcnn_4\u001B[49m\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcnn4.h5\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'cnn_4' is not defined"
     ]
    }
   ],
   "source": [
    "cnn_4.save(\"cnn4.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T09:51:21.727061571Z",
     "start_time": "2024-01-25T09:51:21.681774928Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnn4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(\u001B[43mcnn4\u001B[49m\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m'\u001B[39m], label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTrain Loss\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      2\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(cnn4\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m], label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mValidation Loss\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      3\u001B[0m plt\u001B[38;5;241m.\u001B[39mlegend()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'cnn4' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(cnn4.history['loss'], label='Train Loss')\n",
    "plt.plot(cnn4.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T09:51:21.931592020Z",
     "start_time": "2024-01-25T09:51:21.908854165Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnn4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(\u001B[43mcnn4\u001B[49m\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124macc\u001B[39m\u001B[38;5;124m'\u001B[39m], label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTrain accuracy\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      2\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(cnn4\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_acc\u001B[39m\u001B[38;5;124m'\u001B[39m], label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mValidation accuracy\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      3\u001B[0m plt\u001B[38;5;241m.\u001B[39mlegend()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'cnn4' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(cnn4.history['acc'], label='Train accuracy')\n",
    "plt.plot(cnn4.history['val_acc'], label='Validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is overfiting from the 15th epochs.   \n",
    "So there is no need to continue beyond that with this model and this dataset and the risk of over-interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The second variant for 6 Layer model\n",
    "\n",
    "1. Convolutional input layer, 32 feature maps with a size of 3×3, a rectifier activation function\n",
    "2. Dropout set to 20%\n",
    "3. Convolutional input layer, 32 feature maps with a size of 3×3, a rectifier activation function\n",
    "4. Max Pool layer with size 2×2\n",
    "5. Convolutional input layer, 64 feature maps with a size of 3×3, a rectifier activation function\n",
    "6. Dropout set to 20%\n",
    "7. Convolutional input layer, 64 feature maps with a size of 3×3, a rectifier activation function\n",
    "8. Max Pool layer with size 2×2\n",
    "9. Convolutional input layer, 128 feature maps with a size of 3×3, a rectifier activation function\n",
    "10. Dropout set to 20%\n",
    "11. Convolutional input layer, 128 feature maps with a size of 3×3, a rectifier activation function\n",
    "12. Max Pool layer with size 2×2\n",
    "13. Flatten layer\n",
    "14. Dropout set to 20%\n",
    "15. Fully connected layer with 1024 units and a rectifier activation function and a weight constraint of max norm set to 3\n",
    "16. Dropout set to 20%\n",
    "17. Fully connected output layer with 10 units and a softmax activation function\n",
    "\n",
    "**Exercise :** Create the 6-layer model following the instructions above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T09:51:22.508307646Z",
     "start_time": "2024-01-25T09:51:22.460714728Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 35\u001B[0m\n\u001B[1;32m     32\u001B[0m     model\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n\u001B[0;32m---> 35\u001B[0m cnn_6 \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_6_layers\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[9], line 3\u001B[0m, in \u001B[0;36mmodel_6_layers\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmodel_6_layers\u001B[39m():\n\u001B[0;32m----> 3\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mSequential\u001B[49m()\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;66;03m### Enter your code here (+- 17 lines)\u001B[39;00m\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;66;03m#### layer 1 : (2 lines)\u001B[39;00m\n\u001B[1;32m      6\u001B[0m    \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     30\u001B[0m     \n\u001B[1;32m     31\u001B[0m     \u001B[38;5;66;03m# Compile model \u001B[39;00m\n\u001B[1;32m     32\u001B[0m     model\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "\u001B[0;31mNameError\u001B[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "def model_6_layers():\n",
    "    \n",
    "    model = Sequential()\n",
    "    ### Enter your code here (+- 17 lines)\n",
    "    #### layer 1 : (2 lines)\n",
    "   \n",
    "\n",
    "    #### layer 2 : (2 lines)\n",
    "   \n",
    "\n",
    "    #### layer 3 : (2 lines)\n",
    "\n",
    "    \n",
    "    #### layer 4 : (2 lines)\n",
    "  \n",
    "\n",
    "    #### layer 5 : (2 lines)\n",
    "  \n",
    "\n",
    "    #### layer 6 : (2 lines)\n",
    " \n",
    "\n",
    "    \n",
    "    #### Output (+- 5 lines)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "    ### End of your code \n",
    "    \n",
    "    # Compile model \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "cnn_6 = model_6_layers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice :** Display the summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T09:51:22.890667584Z",
     "start_time": "2024-01-25T09:51:22.844091953Z"
    }
   },
   "outputs": [],
   "source": [
    "### Enter ypur code here (1 line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You should do something like this:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "conv2d_39 (Conv2D)           (None, 32, 32, 32)        896       \n",
    "_________________________________________________________________\n",
    "dropout_30 (Dropout)         (None, 32, 32, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_40 (Conv2D)           (None, 32, 32, 32)        9248      \n",
    "_________________________________________________________________\n",
    "max_pooling2d_20 (MaxPooling (None, 16, 16, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_41 (Conv2D)           (None, 16, 16, 64)        18496     \n",
    "_________________________________________________________________\n",
    "dropout_31 (Dropout)         (None, 16, 16, 64)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_42 (Conv2D)           (None, 16, 16, 64)        36928     \n",
    "_________________________________________________________________\n",
    "max_pooling2d_21 (MaxPooling (None, 8, 8, 64)          0         \n",
    "_________________________________________________________________\n",
    "conv2d_43 (Conv2D)           (None, 8, 8, 128)         73856     \n",
    "_________________________________________________________________\n",
    "dropout_32 (Dropout)         (None, 8, 8, 128)         0         \n",
    "_________________________________________________________________\n",
    "conv2d_44 (Conv2D)           (None, 8, 8, 128)         147584    \n",
    "_________________________________________________________________\n",
    "max_pooling2d_22 (MaxPooling (None, 4, 4, 128)         0         \n",
    "_________________________________________________________________\n",
    "flatten_9 (Flatten)          (None, 2048)              0         \n",
    "_________________________________________________________________\n",
    "dropout_33 (Dropout)         (None, 2048)              0         \n",
    "_________________________________________________________________\n",
    "dense_15 (Dense)             (None, 1024)              2098176   \n",
    "_________________________________________________________________\n",
    "dropout_34 (Dropout)         (None, 1024)              0         \n",
    "_________________________________________________________________\n",
    "dense_16 (Dense)             (None, 10)                10250     \n",
    "=================================================================\n",
    "Total params: 2,395,434\n",
    "Trainable params: 2,395,434\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise :** Fit the model with 15 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T09:51:23.704552736Z",
     "start_time": "2024-01-25T09:51:23.669574096Z"
    }
   },
   "outputs": [],
   "source": [
    "### Enter your code here (1 line) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save your model \n",
    "\n",
    "**Exercise :** Save your model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T09:51:24.071999778Z",
     "start_time": "2024-01-25T09:51:24.033992632Z"
    }
   },
   "outputs": [],
   "source": [
    "### Enter your code here (1 line) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display histogram "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise :** Display histogram with loss and accuracy data in ``cnn6``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T09:51:24.657773322Z",
     "start_time": "2024-01-25T09:51:24.595647640Z"
    }
   },
   "outputs": [],
   "source": [
    "### Display LOSS \n",
    "### Enter your code here (+- 4 lines)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Display ACCURACY\n",
    "### Enter your code here (+- 4 lines)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T09:51:24.792901691Z",
     "start_time": "2024-01-25T09:51:24.773939756Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnn_6' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m scores6l \u001B[38;5;241m=\u001B[39m \u001B[43mcnn_6\u001B[49m\u001B[38;5;241m.\u001B[39mevaluate(x_test, y_test, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccuracy: \u001B[39m\u001B[38;5;132;01m%.2f\u001B[39;00m\u001B[38;5;132;01m%%\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (scores6l[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m100\u001B[39m))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'cnn_6' is not defined"
     ]
    }
   ],
   "source": [
    "scores6l = cnn_6.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores6l[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**My score :**  \n",
    "Accuracy: 77.89%  \n",
    "Epochs : 15  \n",
    "Btach_size : 32  \n",
    "Time : 8 min  \n",
    "GPU : GTX 1050   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment the dataset \n",
    "Last but not least, we have to augment the pictures with the help of a Keras native library ImageDataGenerator. Essentially, you manipulate the pictures in order to cover more ground. It rotates, flipping and shifting the pictures and generates “distorted” images from the initial dataset. You can find more information about this technique here. Finally, we have to compile the model and train the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fit_data_augmentation(model, data_augmentation = True, epochs = epochs, batch_s = batch_size):\n",
    "\n",
    "    if not data_augmentation:\n",
    "        print('Not using data augmentation.')\n",
    "        model.fit(x_train, y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  validation_data=(x_test, y_test),\n",
    "                  shuffle=True)\n",
    "    else:\n",
    "        print('Using real-time data augmentation.')\n",
    "        # This will do preprocessing and realtime data augmentation:\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "            rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            # randomly shift images horizontally (fraction of total width)\n",
    "            width_shift_range=0.1,\n",
    "            # randomly shift images vertically (fraction of total height)\n",
    "            height_shift_range=0.1,\n",
    "            shear_range=0.,  # set range for random shear\n",
    "            zoom_range=0.5,  # set range for random zoom\n",
    "            channel_shift_range=0.,  # set range for random channel shifts\n",
    "            # set mode for filling points outside the input boundaries\n",
    "            fill_mode='nearest',\n",
    "            cval=0.,  # value used for fill_mode = \"constant\"\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False,  # randomly flip images\n",
    "            # set rescaling factor (applied before any other transformation)\n",
    "            rescale=None,\n",
    "            preprocessing_function=None,\n",
    "            # image data format, either \"channels_first\" or \"channels_last\"\n",
    "            data_format=None,\n",
    "            # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "            validation_split=0.0)\n",
    "\n",
    "        # Compute quantities required for feature-wise normalization\n",
    "        # (std, mean, and principal components if ZCA whitening is applied).\n",
    "        datagen.fit(x_train)\n",
    "\n",
    "        # Fit the model on the batches generated by datagen.flow().\n",
    "        model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                         batch_size=batch_s),\n",
    "                            steps_per_epoch=len(x_train) / batch_s,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(x_test, y_test),\n",
    "                            workers=4)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_data_augmentation(cnn_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limits overfiting with Early Stopping\n",
    "\n",
    "Keras supports the early stopping of training via a callback called EarlyStopping.\n",
    "\n",
    "This callback allows you to specify the performance measure to monitor, the trigger, and once triggered, it will stop the training process.\n",
    "\n",
    "The EarlyStopping callback is configured when instantiated via arguments.\n",
    "\n",
    "The “monitor” allows you to specify the performance measure to monitor in order to end training. Recall from the previous section that the calculation of measures on the validation dataset will have the ‘val_‘ prefix, such as ‘val_loss‘ for the loss on the validation dataset.\n",
    "\n",
    "````python \n",
    "es = EarlyStopping(monitor='val_loss')\n",
    "````\n",
    "\n",
    "Based on the choice of performance measure, the “mode” argument will need to be specified as whether the objective of the chosen metric is to increase (maximize or ‘max‘) or to decrease (minimize or ‘min‘).\n",
    "\n",
    "For example, we would seek a minimum for validation loss and a minimum for validation mean squared error, whereas we would seek a maximum for validation accuracy. \n",
    "\n",
    "````python \n",
    "es = EarlyStopping(monitor='val_loss', mode='min')\n",
    "````\n",
    "By default, mode is set to ‘auto‘ and knows that you want to minimize loss or maximize accuracy.\n",
    "\n",
    "That is all that is needed for the simplest form of early stopping. Training will stop when the chosen performance measure stops improving. To discover the training epoch on which training was stopped, the “verbose” argument can be set to 1. Once stopped, the callback will print the epoch number.\n",
    "\n",
    "````python\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "````\n",
    "Often, the first sign of no further improvement may not be the best time to stop training. This is because the model may coast into a plateau of no improvement or even get slightly worse before getting much better.\n",
    "\n",
    "We can account for this by adding a delay to the trigger in terms of the number of epochs on which we would like to see no improvement. This can be done by setting the “patience” argument.\n",
    "\n",
    "````python\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "````\n",
    "The exact amount of patience will vary between models and problems. Reviewing plots of your performance measure can be very useful to get an idea of how noisy the optimization process for your model on your data may be.\n",
    "\n",
    "By default, any change in the performance measure, no matter how fractional, will be considered an improvement. You may want to consider an improvement that is a specific increment, such as 1 unit for mean squared error or 1% for accuracy. This can be specified via the “min_delta” argument.\n",
    "\n",
    "````python\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', baseline=0.4)\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then update the call to the fit() function and specify a list of callbacks via the **“callback”** argument.\n",
    "````python\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=4000, verbose=0, callbacks=[es])\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "cnn_4 = model_4_layers()\n",
    "cnn_4.summary()\n",
    "es = EarlyStopping(monitor='val_loss', mode='min',  verbose=1, patience=5)\n",
    "history = cnn_4.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=4000, verbose=1, callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you go!  \n",
    "As soon as keras notices that the val_loss no longer decreases 5 times in a row, he will stop the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save your best model ! \n",
    "\n",
    "There is one last thing we need to do. Save the best model. Indeed, the last trained model is not necessarily the best.  To do this we will use the ``ModelCheckpoint()`` method which will allow us to save only the best trained model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = cnn_4.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=4000, verbose=1, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
