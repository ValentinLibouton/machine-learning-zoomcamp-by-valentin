{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qu'est-ce qu'un réseau neuronal ?\n",
    "Un réseau neuronal est un ensemble de neurones formels interconnectés qui résout des problèmes complexes tels que la reconnaissance de formes ou le traitement du langage naturel en ajustant les coefficients de pondération dans une phase d'apprentissage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctionnement du réseau neuronal\n",
    "Un réseau neuronal s'inspire du fonctionnement des neurones biologiques et prend forme dans un ordinateur sous la forme d'un algorithme.\n",
    "Le réseau neuronal peut se modifier en fonction des résultats de ses actions, ce qui permet l'apprentissage et la résolution de problèmes sans algorithme, et donc sans programmation traditionnelle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![biologic vs artificial neuron](./img/bioVSart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour nos besoins, nous pouvons modéliser ce neurone en fonction d'un ensemble d'entrées, qui reçoit une somme pondérée de ces entrées à l'aide de poids, ajoute un biais et fournit un nombre sur la base d'une fonction d'activation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![one neuron](./img/nl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Les poids** peuvent être considérés comme un ensemble de boutons qui peuvent être ajustés pour obtenir différentes sorties.\n",
    "\n",
    "\n",
    "- **Le biais** peut être considéré comme un autre bouton qui décide quand un neurone reste inactif ou, en d'autres termes, dans quelle mesure la somme pondérée doit être élevée pour que le neurone soit significativement actif.\n",
    "\n",
    "\n",
    "- **La fonction d'activation** Nous verrons plus en détail dans le paragraphe suivant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qu'est-ce qu'une fonction d'activation ?\n",
    "\n",
    "La fonction d'activation est inspirée du \"potentiel d'action\", un phénomène électrique entre deux neurones biologiques.\n",
    "\n",
    "Commençons par un petit rappel du cours de biologie : Un neurone possède un corps cellulaire, un axone qui lui permet d'envoyer des messages à d'autres neurones et des dendrites qui lui permettent de recevoir des signaux d'autres neurones.\n",
    "\n",
    "![Image de neuronne](./img/cn.jpg)\n",
    "\n",
    "Le neurone reçoit des signaux d'autres neurones par l'intermédiaire des dendrites. Le poids associé à une dendrite, appelé poids synaptique, est multiplié par le signal entrant. Les signaux des dendrites sont accumulés dans le corps cellulaire et si l'intensité du signal résultant dépasse un certain seuil, le neurone transmet le message à l'axone. Dans le cas contraire, le signal est tué par le neurone et ne se propage plus. Le potentiel d'action est donc la variation de l'intensité du signal indiquant si la communication doit avoir lieu ou non.\n",
    "\n",
    "La fonction d'activation décide de transmettre ou non le signal. Dans ce cas, il s'agit d'une fonction simple avec un seul paramètre : le seuil. Or, lorsque nous apprenons quelque chose de nouveau, le seuil et la probabilité de connexion (appelée poids synaptique) de certains neurones changent. Cela crée de nouvelles connexions entre les neurones, ce qui permet au cerveau d'apprendre de nouvelles choses.\n",
    "\n",
    "Voyons maintenant comment tout cela fonctionne avec un réseau neuronal artificiel : Les valeurs entrantes dans un neurone (x1, x2, x3, ..., xn) sont multipliées par leurs poids associés (référence au poids synaptique) (w1, w2, w3, ..., wn). Ces multiplications sont ensuite additionnées et le biais (référence au seuil) est ajouté. L'image ci-dessous montre la formule de calcul.\n",
    "\n",
    "Le but de l'activation est de transformer le signal afin d'obtenir une valeur de sortie à partir de transformations complexes entre les entrées. Pour ce faire, la fonction d'activation doit être non linéaire. C'est cette non-linéarité qui permet de créer de telles transformations.\n",
    "\n",
    "Les exemples de fonctions d'activation les plus couramment utilisés sont sigmoïde, softmax, ReLU, tanh, etc.\n",
    "\n",
    "![fonctions d'activation](./img/reLU.png)\n",
    "\n",
    "**Sigmoïde :**\n",
    "La principale raison pour laquelle nous utilisons la fonction sigmoïde est qu'elle existe entre (0 et 1). Comme la probabilité d'une chose n'existe qu'entre 0 et 1, la fonction sigmoïde est le bon choix.\n",
    "\n",
    "**Tanh ou tangente hyperbolique :**\n",
    "Tanh ressemble à la sigmoïde logistique, mais en mieux. La plage de la fonction tanh est comprise entre -1 et 1. tanh est également sigmoïdale (s - en forme). L'avantage est que les entrées négatives sont fortement négatives et que les entrées nulles sont proches de zéro dans le graphique de tanh.\n",
    "\n",
    "ReLU (Rectified Linear Unit) : **ReLU (Rectified Linear Unit) :**\n",
    "La ReLU est la fonction d'activation la plus utilisée dans le monde à l'heure actuelle, puisqu'elle est utilisée dans presque tous les réseaux neuronaux convolutifs ou l'apprentissage profond.\n",
    "\n",
    "Il en existe d'autres qui sont moins utilisées. Je vous laisse consulter Google pour le savoir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure du réseau\n",
    "Maintenant que nous savons comment fonctionne un neurone unique, nous pouvons les connecter ensemble pour former un réseau sous forme de couches.\n",
    "Un réseau neuronal artificiel n'est donc qu'une fonction composite surfaite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![multicouche](./img/multi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un réseau neuronal typique se compose de trois types de couches :\n",
    "\n",
    "- **La couche d'entrée : les points de données donnés sont introduits dans cette couche. Il ne peut y avoir qu'une seule couche d'entrée. Le nombre de neurones dans cette couche est égal au nombre d'entrées. Imaginons qu'en entrée il y ait une photo de 28 pixels par 28 pixels. Nous avons donc besoin d'un neurone par pixel, ce qui fait 784 neurones.\n",
    "\n",
    "\n",
    "- **Les couches cachées:** Ce sont les couches qui essaient de trouver des modèles dans les entrées pour obtenir les sorties dont nous avons besoin. Un réseau peut avoir un nombre illimité de couches cachées.\n",
    "\n",
    "\n",
    "- Cette couche nous donne les prédictions du réseau, c'est-à-dire les sorties que le réseau pense être correctes compte tenu de ses paramètres actuels (poids et biais de chaque neurone). Le nombre de neurones dans cette couche est égal au nombre de valeurs que nous devons prédire. Imaginons que nous voulions créer un algorithme qui reconnaisse des chiffres. Comme il y a dix chiffres à reconnaître (0 à 9), il y aura 10 neurones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![neural network](./img/3lnn.svg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
